{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the required packages"
      ],
      "metadata": {
        "id": "oJvlp3TDfadq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ZzzMiWfAMjzQ"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec, FastText\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.corpus import stopwords\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import gensim\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(action = 'ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1bnl15HOR3x",
        "outputId": "661b0d1f-de63-4e94-9189-81c1f894719c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "_i6csbDcdelU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using sklearn to get \"20 News group\" Dataset"
      ],
      "metadata": {
        "id": "ea3yy4uFfhh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism','rec.sport.baseball','talk.politics.mideast','comp.graphics', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',categories=categories, remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "BMcLgCmTNkRZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating functions to do preprocessing of the data"
      ],
      "metadata": {
        "id": "Kz-jVgcNf4bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text,stem=False, stop=False, sent=False):\n",
        "\n",
        "    # Remove punctuations\n",
        "    exclude = set(string.punctuation)\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    if stop:\n",
        "        stop = stopwords.words('english')\n",
        "        tokens =[word for word in tokens if word not in stop]\n",
        "        tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    if stem:\n",
        "        stemmer = PorterStemmer()\n",
        "        tokens = [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "    if sent:\n",
        "        tokens = ' '.join(tokens)\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "Qv87jDzKNE0W"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_news(articles):\n",
        "\n",
        "    clean = []\n",
        "\n",
        "    for article in articles:\n",
        "        clean.append(preprocessing(article,stop=True,sent=False, stem=False))\n",
        "\n",
        "    return clean"
      ],
      "metadata": {
        "id": "JsRaT9MnOayZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are downloading the pre trained models"
      ],
      "metadata": {
        "id": "k8AWyberg_Lf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding Techniques"
      ],
      "metadata": {
        "id": "e05VymCYdWt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(gensim.downloader.info()['models'].keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGyhRcD0ZT-M",
        "outputId": "19f93777-52e8-46ad-dd68-8fe4348c717b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec:**\n",
        "\n",
        "Word2Vec can make strong estimates about a word’s meaning based on their occurrences in the text. These estimates yield word associations with other words in the corpus."
      ],
      "metadata": {
        "id": "vHkuVLvZ0QUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPEE2krqZfP0",
        "outputId": "e2e2ea02-0f4a-4639-c355-57077017f53c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastText:**\n",
        "\n",
        "FastText is a word embedding technique that provides embedding to the character n-grams. It is the extension of the word2vec model."
      ],
      "metadata": {
        "id": "GFGQS2Nk1O7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft = api.load('fasttext-wiki-news-subwords-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwzYS_WHFq4t",
        "outputId": "da32c5cd-af5d-48f2-cca3-c142ed8de5d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison Word2Vec and FastText**\n",
        "\n",
        "Word2Vec works on the word level, while fastText works on the character n-grams.\n",
        "\n",
        "Word2Vec cannot provide embeddings for out-of-vocabulary words, while fastText can provide embeddings for OOV words.\n",
        "\n",
        "FastText can provide better embeddings for morphologically rich languages compared to word2vec."
      ],
      "metadata": {
        "id": "5DM3swmB2xTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of semantics, Word2Vec performs better."
      ],
      "metadata": {
        "id": "Ft_NKeN64pf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pre-trained models, converting the text to vectors. Here, we are using Word2Vec and FastText"
      ],
      "metadata": {
        "id": "GBBpf7j_gdb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_vec(sent):\n",
        "    vector_size = wv.vector_size\n",
        "    wv_res = np.zeros(vector_size)\n",
        "    # print(wv_res)\n",
        "    ctr = 1\n",
        "    for w in sent:\n",
        "        if w in wv:\n",
        "            ctr += 1\n",
        "            wv_res += wv[w]\n",
        "    wv_res = wv_res/ctr\n",
        "    return wv_res"
      ],
      "metadata": {
        "id": "XXcyHpTfQwGT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_vec_ft(sent):\n",
        "    vector_size = ft.vector_size\n",
        "    ft_res = np.zeros(vector_size)\n",
        "    # print(wv_res)\n",
        "    ctr = 1\n",
        "    for w in sent:\n",
        "        if w in ft:\n",
        "            ctr += 1\n",
        "            ft_res += ft[w]\n",
        "    ft_res = ft_res/ctr\n",
        "    return ft_res"
      ],
      "metadata": {
        "id": "e1OJ9eQDIIHp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is to calculate AUC ROC for each class"
      ],
      "metadata": {
        "id": "lFcjMNVNlNQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
        "\n",
        "    #creating a set of all the unique classes using the actual class list\n",
        "    unique_class = set(actual_class)\n",
        "    roc_auc_dict = {}\n",
        "    for per_class in unique_class:\n",
        "\n",
        "        #creating a list of all the classes except the current class\n",
        "        other_class = [x for x in unique_class if x != per_class]\n",
        "\n",
        "        #marking the current class as 1 and all other classes as 0\n",
        "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
        "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
        "\n",
        "        #using the sklearn metrics method to calculate the roc_auc_score\n",
        "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
        "        roc_auc_dict[per_class] = roc_auc\n",
        "\n",
        "    return roc_auc_dict"
      ],
      "metadata": {
        "id": "D4MOEM2yv2cF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the data from sklearn to Pandas"
      ],
      "metadata": {
        "id": "Rd1DaElohRSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(data=newsgroups_train.data, columns = ['News'])\n",
        "test_df = pd.DataFrame(data=newsgroups_test.data, columns = ['News'])"
      ],
      "metadata": {
        "id": "koefmIdwgOBK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling preprocessing functions on the data, to tokenize the text"
      ],
      "metadata": {
        "id": "ig0zXFRyhZpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['tokens'] = clean_news(train_df.News)\n",
        "test_df['tokens'] = clean_news(test_df.News)"
      ],
      "metadata": {
        "id": "oskQKgN5g1x6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the function to vectorize the tokens, here we are using Word2Vec"
      ],
      "metadata": {
        "id": "gwINN71pidbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['vec'] = train_df['tokens'].apply(sent_vec)\n",
        "test_df['vec'] = test_df['tokens'].apply(sent_vec)"
      ],
      "metadata": {
        "id": "-nj667zffmYP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a target variable from the dataset"
      ],
      "metadata": {
        "id": "3MmOoXDEiqPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['target'] = newsgroups_train.target\n",
        "test_df['target'] = newsgroups_test.target\n",
        "\n",
        "y_train = train_df['target'].to_list()\n",
        "y_test = test_df['target'].to_list()"
      ],
      "metadata": {
        "id": "jR6ZdWZviGjj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count of each category"
      ],
      "metadata": {
        "id": "_yeykxfe9-f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JacxaZh89xde",
        "outputId": "b3f2d218-9f84-480e-8741-d118821733ae"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    597\n",
              "3    593\n",
              "1    584\n",
              "4    564\n",
              "0    480\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrexWuGl93hQ",
        "outputId": "e3b584f3-2135-46ef-98a1-87af8814b741"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    397\n",
              "3    394\n",
              "1    389\n",
              "4    376\n",
              "0    319\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the vectors from the pandas dataframe to list to pass"
      ],
      "metadata": {
        "id": "983p3ohki6tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df['vec'].to_list()\n",
        "X_test = test_df['vec'].to_list()"
      ],
      "metadata": {
        "id": "GnovcM-7iglv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification"
      ],
      "metadata": {
        "id": "KwBUIzIwCOEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine**\n",
        "\n",
        "SVM (Support vector machine) is an efficient classification method when the feature vector is high dimensional. Using SVM as classifier"
      ],
      "metadata": {
        "id": "YPnBQnGSjgnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zvcpy8dhNvF2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the classifier with test data"
      ],
      "metadata": {
        "id": "RSud83fQkH2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = svm_model_linear.predict(X_test)\n",
        "accuracy = svm_model_linear.score(X_test, y_test)\n",
        "print(\"Support Vector Machine Accuracy with Word2Vec:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQyAga2Sivfx",
        "outputId": "ba3eaf34-189c-4fe6-f2e7-0963ab13c64b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine Accuracy with Word2Vec: 0.8117333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics report for the classifier using Word2Vec"
      ],
      "metadata": {
        "id": "JzBvbhKQk6gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, predicted, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS12gNPSSJ0o",
        "outputId": "7ce1d552-1927-4d4c-dbab-ff1941577261"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.694     0.718     0.706       319\n",
            "           1      0.878     0.866     0.872       389\n",
            "           2      0.811     0.899     0.853       397\n",
            "           3      0.812     0.789     0.801       394\n",
            "           4      0.852     0.766     0.807       376\n",
            "\n",
            "    accuracy                          0.812      1875\n",
            "   macro avg      0.809     0.808     0.808      1875\n",
            "weighted avg      0.813     0.812     0.812      1875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC for SVM using Word2Vec"
      ],
      "metadata": {
        "id": "pz-RpNWpmJd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_dict = roc_auc_score_multiclass(y_test, predicted)\n",
        "roc_auc_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owat19rEPx76",
        "outputId": "f34c458b-f0f1-44b5-e0ee-9341abedbe62"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.8264791564255265,\n",
              " 1: 0.9173476872402924,\n",
              " 2: 0.9215436818084211,\n",
              " 3: 0.8703621506938994,\n",
              " 4: 0.8663009382141286}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the function to vectorize the tokens, here we are using FastText"
      ],
      "metadata": {
        "id": "zzwGktNWnWCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['vec_ft'] = train_df['tokens'].apply(sent_vec_ft)\n",
        "test_df['vec_ft'] = test_df['tokens'].apply(sent_vec_ft)"
      ],
      "metadata": {
        "id": "d15Gp-1UIdxU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the vectors from the pandas dataframe to list to pass"
      ],
      "metadata": {
        "id": "kXZuDmEnnjWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ft = train_df['vec_ft'].to_list()\n",
        "X_test_ft = test_df['vec_ft'].to_list()"
      ],
      "metadata": {
        "id": "k4jWNPvGJZe9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Support Vector Machine as classifier, to compare the results"
      ],
      "metadata": {
        "id": "rgHX8M-9ntgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train_ft, y_train)"
      ],
      "metadata": {
        "id": "uNZE2_NWBBUB"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the classifier with test data"
      ],
      "metadata": {
        "id": "99cYiHRDov0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ft = svm_model_linear.predict(X_test_ft)\n",
        "accuracy_ft = svm_model_linear.score(X_test_ft, y_test)\n",
        "print(\"Support Vector Machine Accuracy with FastText:\", accuracy_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfpR60T7BWjY",
        "outputId": "31452f34-f712-4887-d7ea-ca25412086a7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine Accuracy with FastText: 0.7669333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics report for the classifier using FastText"
      ],
      "metadata": {
        "id": "mQl8i9VRpA1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, predicted_ft, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A6Rvqj4BX2F",
        "outputId": "70110658-1900-4a1b-f59e-093df0ee61ea"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.602     0.677     0.637       319\n",
            "           1      0.820     0.830     0.825       389\n",
            "           2      0.781     0.829     0.804       397\n",
            "           3      0.756     0.754     0.755       394\n",
            "           4      0.886     0.726     0.798       376\n",
            "\n",
            "    accuracy                          0.767      1875\n",
            "   macro avg      0.769     0.763     0.764      1875\n",
            "weighted avg      0.774     0.767     0.769      1875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC for SVM using FastText"
      ],
      "metadata": {
        "id": "OPUcVgL6pDcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_dict = roc_auc_score_multiclass(y_test, predicted_ft)\n",
        "roc_auc_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9F_Aj7sQjwN",
        "outputId": "01969359-001b-4539-bbb0-860bbcf31a07"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.7926068369180681,\n",
              " 1: 0.8912774585073368,\n",
              " 2: 0.8832345432421101,\n",
              " 3: 0.8444930198761299,\n",
              " 4: 0.8513574652605282}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of SVM:**\n",
        "*   SVM works relatively well when there is a clear margin of separation\n",
        "between classes.\n",
        "*   It is more effective in high dimensional spaces.\n",
        "*   It is relatively memory efficient.\n",
        "\n",
        "**Disadvantages of SVM:**\n",
        "*   SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
        "*   In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform.\n",
        "*   SVM algorithm is not suitable for large data sets."
      ],
      "metadata": {
        "id": "8WtDjDUY_ZbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary based on Metrics**\n",
        "\n",
        "Based on the accuracy of SVM on both Word2Vec and FastText, Word2Vec is performing better with the 81% with ROC above 0.82 for all classes. While FastText gave accuracy 76% with ROC above 0.79"
      ],
      "metadata": {
        "id": "7ZYbHsONAiIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Clustering"
      ],
      "metadata": {
        "id": "fKpX23MSCAax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Means**\n",
        "\n",
        "K-means is a centroid-based clustering algorithm, where we calculate the distance between each data point and a centroid to assign it to a cluster.\n",
        "\n",
        "As we already know number of classes in the data. We are fixing the number of clusters. Generally, the number of cluster will be determined based on the Elbow method."
      ],
      "metadata": {
        "id": "lEIYd2lTEH8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a variable to store the actual number of categories in the data"
      ],
      "metadata": {
        "id": "gxbM7bivpKDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_train_k = np.unique(train_df['target']).shape[0]\n",
        "true_test_k = np.unique(test_df['target']).shape[0]"
      ],
      "metadata": {
        "id": "mv5vzQb12Ita"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using KMeans to cluster the data, by passing the vectors created using Word2Vec"
      ],
      "metadata": {
        "id": "8YmbJyr6plFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "km = KMeans(n_clusters = true_train_k, random_state = 0, n_init='auto')\n",
        "km.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "FZIp9Fi61jfR",
        "outputId": "6878ae2e-d21f-4a1b-8281-44216d7e9f0b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=5, n_init='auto', random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5, n_init=&#x27;auto&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5, n_init=&#x27;auto&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = km.predict(X_test)"
      ],
      "metadata": {
        "id": "rK3d2MnlKgAk"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for the clusters created"
      ],
      "metadata": {
        "id": "r8Bnkjj7qeXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(train_df['target'], km.labels_))\n",
        "print(\"Completeness: %0.3f\" % metrics.completeness_score(train_df['target'], km.labels_))\n",
        "print(\"V-measure: %0.3f\" % metrics.v_measure_score(train_df['target'], km.labels_))\n",
        "print(\"Adjusted Rand-Index: %.3f\"\n",
        "      % metrics.adjusted_rand_score(train_df['target'], km.labels_))\n",
        "print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X_train, km.labels_, metric='euclidean'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-YXwfaNqYEd",
        "outputId": "b6d1e7b2-c3e2-4c1a-ad32-8ce4d5c63098"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homogeneity: 0.368\n",
            "Completeness: 0.430\n",
            "V-measure: 0.397\n",
            "Adjusted Rand-Index: 0.389\n",
            "Silhouette Coefficient: 0.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using KMeans to cluster the data, by passing the vectors created using FastText"
      ],
      "metadata": {
        "id": "Vn0sq9UKqUnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "km = KMeans(n_clusters = true_train_k, random_state = 0, n_init='auto')\n",
        "km.fit(X_train_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "9O7upmbk1xJQ",
        "outputId": "154c52c7-9e8c-46a9-a72d-6f4b1d4fa47c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=5, n_init='auto', random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5, n_init=&#x27;auto&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5, n_init=&#x27;auto&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ft = km.predict(X_test_ft)"
      ],
      "metadata": {
        "id": "Za0gxAyMLOuu"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for the clusters created"
      ],
      "metadata": {
        "id": "VDrZP-RCqoJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(train_df['target'], km.labels_))\n",
        "print(\"Completeness: %0.3f\" % metrics.completeness_score(train_df['target'], km.labels_))\n",
        "print(\"V-measure: %0.3f\" % metrics.v_measure_score(train_df['target'], km.labels_))\n",
        "print(\"Adjusted Rand-Index: %.3f\"\n",
        "      % metrics.adjusted_rand_score(train_df['target'], km.labels_))\n",
        "print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X_train_ft, km.labels_, metric='euclidean'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85AIeZFNqkn-",
        "outputId": "67a59b7e-ecbd-4c39-db52-7690a932aca8"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homogeneity: 0.030\n",
            "Completeness: 0.057\n",
            "V-measure: 0.039\n",
            "Adjusted Rand-Index: 0.027\n",
            "Silhouette Coefficient: 0.169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages of KMeans:**\n",
        "\n",
        "\n",
        "*   It is very easy to implement.\n",
        "*   Tighter clusters are formed with K-means.\n",
        "*   If we have large number of variables then, K-means would be faster than Hierarchical clustering.\n",
        "\n",
        "**Disadvantages of KMeans:**\n",
        "\n",
        "\n",
        "\n",
        "*   It is a bit difficult to predict the number of clusters i.e. the value of k.\n",
        "*   It is not good in doing clustering job if the clusters have a complicated geometric shape.\n",
        "*   Order of data will have strong impact on the final output.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "so8TBNvLFHjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary based on Metrics**\n",
        "\n",
        "Silhouette score returns the average silhouette coefficient applied on all the samples. The Silhouette Coefficient is calculated by using the mean of the distance of the intra-cluster and nearest cluster for all the samples.\n",
        "\n",
        "The Silhouette score is comparitively better for the model with FastText (0.169).\n",
        "\n",
        "V-Measure is a measure of the goodness of our clustering algorithm we can consider the harmonic average between homogeneity and completeness and obtain the V-measure.\n",
        "\n",
        "Based on the V-Measure (0.397), the model with Word2Vec is better."
      ],
      "metadata": {
        "id": "5o8vNWS4eCsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Improvement"
      ],
      "metadata": {
        "id": "S3SsBjQ2dBTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset which we used in this assignment is the newsgroup, which is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. The possible improvements are\n",
        "\n",
        "*  Using Lemmatization instead of Stemming technique to bring words to its proper base forms.\n",
        "*  Expanding the abbrevations could add more value to the data.\n",
        "*  Tuning the hyperparameters of the algorithms to give better results."
      ],
      "metadata": {
        "id": "k_-gpWCvdKyC"
      }
    }
  ]
}